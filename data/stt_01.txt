[00:00.000 --> 00:12.320]  안녕하십니까. 강의 시작하겠습니다.

[00:12.320 --> 00:18.920]  오늘은 Python 강의의 NumPy랑 Pandas 모듈을 이해를 돕기 위해서

[00:18.920 --> 00:25.520]  머신러닝 개념과 데이터 분석 개념에 대해서 강의를 진행하도록 하겠습니다.

[00:25.520 --> 00:35.400]  지금 화면에 나와있듯이 현재 저희는 4차 산업혁명 시대에 살고 있고 그 근간이 되는 빅데이터 그리고 빅데이터를 활용한 AI 기술을

[00:35.400 --> 00:45.640]  저희는 사용하고 있는데 흔히 AI라고 하는 것은 지금 페이지에 나와있듯이 머신러닝, 딥러닝

[00:45.640 --> 00:49.240]  이렇게 구성되어 있습니다.

[00:50.040 --> 00:54.160]  머신러닝이라는 것은 우리말로는 기계학습이라고 하는데

[00:54.160 --> 01:02.000]  정의하기 힘든 데이터를 활용해서 룰을 정립하는 데 많은 도움을 주었습니다.

[01:02.000 --> 01:12.200]  과거에는 화면에 나와있듯이 인풋데이터랑 그리고 알고리즘이라고 불리는 프로그램을 통해서

[01:12.200 --> 01:19.480]  컴퓨터가 결과를 산출하는 작업을 했다면 현재는 인풋데이터와 그리고 아웃풋데이터를 통해서

[01:19.480 --> 01:26.560]  제가 알고리즘을 만드는 역할을 하고 있습니다. 이 역할을 하는 중추적인 것이 머신러닝이고

[01:26.560 --> 01:34.360]  인풋데이터와 그리고 아웃풋데이터를 통해서 알고리즘 혹은 프로그램을 만든다.

[01:34.360 --> 01:47.440]  이건 예전에 수학시간을 생각해보면 정말 많이 해봤던 작업인데 이게 인풋과 아웃풋으로 그에 해당하는 함수를 만드는 것이라고 생각하시면 됩니다.

[01:47.440 --> 01:55.440]  단편적으로 머신러닝, 딥러닝, 성공기능은 함수를 만드는 작업이라고 생각하시면 됩니다.

[01:55.480 --> 02:04.360]  인풋과 아웃풋을 넣고 그것을 결정짓는 함수를 만드는 작업이 머신러닝, 딥러닝, AI입니다.

[02:04.360 --> 02:16.680]  단순하게 지금 그림에 나와있듯이 y는 3x라는 단순한 수식은 데이터 형태가 일정한 경우에는 10배 이렇게 찾아낼 수 있는 함수인데

[02:16.680 --> 02:31.600]  복잡한 데이터에서 이런 관계식을 설정하기가 굉장히 힘들겠죠. 그래서 보통 인간은 여러가지 식을 가정하고 하나하나 인풋데이터와 아웃풋데이터를 넣어가면서

[02:31.600 --> 02:44.160]  정답을 찾아가는데 머신러닝은 이런 데이터를 통해서 식을 하나하나 넣어가면서 계속 그 함수를 업데이트 해가는

[02:44.160 --> 02:53.120]  것이라고 생각하면 됩니다. 여기서 머신러닝, 기계학습에서의 러닝은 즉 학습은

[02:53.120 --> 02:55.680]  데이터를

[02:58.920 --> 03:11.040]  데이터를 통해서 계속 식을 업데이트 해 나가는 것을 학습이라고 생각하시면 되는데 이 학습의 수학적인 개념은 제가 앞으로 수업시간에 설명을

[03:11.040 --> 03:20.080]  하도록 하겠습니다. 그럼 머신러닝이 왜 갑자기 현대 데이터 시대에 많이 쓰였을까요?

[03:20.080 --> 03:30.080]  앞서 말했듯이 과거의 방법과는 다른 머신러닝이란 방법으로 다양한 분석법적인 접근이 이 시대에는 가능해졌는데

[03:30.080 --> 03:35.840]  예를 하나 들어 볼게요

[03:36.840 --> 03:47.960]  이게 사람의 행동을 모바일 액티비티 트래커라는 앱을 통해서 분석하는 건데

[03:47.960 --> 03:57.840]  y-axis, x-axis, z-axis의 추구에 따라 데이터가 다양하게 들어오는 건데

[03:57.920 --> 04:08.400]  조깅할 때, 걸을 때, 앉았을 때, 일어섰을 때의 데이터가 이렇게 다양하게 들어옵니다. 과거의 일반적인 방법은 이런 데이터를 보고

[04:08.400 --> 04:18.040]  워킹이라고 생각하시면 이런 맥스값이나 밍값, 그리고 조깅도 맥스값이나 밍값, 시팅도 맥스밍이 있을 수 있고

[04:18.040 --> 04:27.120]  그리고 에버리지나 그런 표준 편창 이런 걸 이용해서 분석을 하는 거였는데

[04:27.120 --> 04:37.320]  근데 이것에 대한 분석이 모든 사람 그리고 모든 장소에 대해 일반성을 갖는다는 것은 어렵습니다.

[04:37.320 --> 04:41.840]  그리고 여러가지 제약사항이 또 있는데

[04:41.840 --> 04:51.000]  예를 들면 만약에 어떤 여자가 이 폰을 가방에 놔두고 혹은 앞주머니에 놔두고

[04:51.000 --> 04:58.800]  움직였을 때 이것에 대한 스탠다드 디비에이션이나 에버리지 값이나 맥스밍이 다르게 나올 수 있겠죠.

[04:58.800 --> 05:04.280]  그래서 과거의 방식은 이러한 한계성이 있는데

[05:04.280 --> 05:10.920]  현재의 머신러닝 방법은 이 한계성을 어느 정도 보완을 한다고 생각하시면 됩니다.

[05:10.920 --> 05:17.400]  그래도 이런 휴리스틱 경험적인 방법이 꼭 안좋은 건 아니고

[05:17.400 --> 05:23.000]  지금도 사실 머신러닝, 딥러닝 쪽에서 휴리스틱한 방법을 베이스로 두고

[05:23.000 --> 05:31.320]  그 근간을 두고 머신러닝이랑 딥러닝을 이렇게 덧붙여서 결과를 내는 방식도 많거든요.

[05:32.240 --> 05:39.040]  그래서 적절한 조화가 필요한데 아무튼 이런 제약사항을 극복하기 위해서

[05:39.040 --> 05:42.400]  머신러닝을 사용한다고 했을 때

[05:42.680 --> 05:50.040]  예를 들면 기시전 트리를 사용한다고 했을 때는 이런 밍값이나 스탠다드 디비에이션이나 맥스밍을 다양하게

[05:50.040 --> 05:57.560]  가지마다 이렇게 정도를 설정해 주어서 데이터를 분석하는 방법이 있을 수 있겠습니다.

[05:57.600 --> 06:04.080]  혹은 또 다양한 방법이 많은데 기시전 트리 말고도 랜덤 포레스트나

[06:04.080 --> 06:13.160]  라이브 베이스 클래시파이어나 서버드 레코머징, 미뉴 리그레이션, 히든 마크로 모델 등등의 모델들이 많은데

[06:13.160 --> 06:22.840]  이런 모델들은 제가 수업하면서 직접 구현도 해보고 설명도 앞으로 더 하면서

[06:22.840 --> 06:32.040]  얘기를 나누도록 하겠습니다. 그런데 이런 머신러닝 방법도 단점이 있는데 이런 머신러닝은

[06:32.040 --> 06:41.960]  사전 지식이 없으면 데이터를 프리 프로세싱 하거나 피처 익스트랙션, 전처리 하거나 특히 추출을 하기에

[06:42.280 --> 06:52.080]  힘이 들 수 있습니다. 예를 들면 리니어 리그레이션으로 머신러닝을 한다고 가정하면

[06:52.080 --> 07:03.520]  이 데이터가 리니어 한지 먼저 파악을 해야 되고 기시전 트리는 아까 보여드렸듯이 이런 노드의 갯수나 이런 가지의 갯수

[07:03.520 --> 07:09.160]  그리고 깊이 등을 설정을 해야 되고 혹은 KNN

[07:09.160 --> 07:17.320]  K-Nearest Neighborhood 알고리즘 같은 경우에는 어떤 특징으로 군집을 설정할지에 대한

[07:17.320 --> 07:24.120]  데이터의 특징 추출이 필수적입니다. 특징 추출이라는게 피처 익스트랙션이라고 생각하시면 되고

[07:24.120 --> 07:33.840]  이 피처 익스트랙션이 기반이 돼야 머신러닝이 이루어지는 건데 이 단점을 또 해결하기 위해서 딥러닝이라는 방법을 씁니다.

[07:33.840 --> 07:42.280]  딥러닝은 앞서 머신러닝에서 필수적이라고 말씀드렸던 피처 익스트랙션을 할 필요 없이

[07:42.280 --> 07:48.880]  딥러닝 내부에서는 학습을 하면서 그 노드마다 웨이츠랑 바이어스를 업데이트 하면서

[07:48.880 --> 07:54.080]  피처 익스트랙션이 자동으로 되고 데이터를 분석을 할 수 있습니다.

[07:54.520 --> 08:00.680]  이 딥러닝도 제가 계속 수업시간에 좀 더 수학적인 이론이랑

[08:00.680 --> 08:08.360]  그리고 모델을 보여드리면서 좀 더 자세히 설명을 하도록 하겠습니다.

[08:08.360 --> 08:15.760]  딥러닝이랑 머신러닝을 데이터에 적절하게 사용하는 것이 현재 주요한 테스트이고

[08:15.760 --> 08:23.720]  일반적으로 딥러닝은 데이터가 많을수록 그리고 모델 사이즈가 클수록 더 좋은 성능을 가진다고 합니다.

[08:23.720 --> 08:30.880]  실제로도 이미지나 보이스나 이런 데이터가 많고 모델 사이즈가 큰 경우에

[08:30.880 --> 08:40.120]  정말 좋은 성능을 가집니다. 하지만 적절한 데이터에 적절한 딥러닝 알고리즘을 활용해야 되는 것이 중요하며

[08:40.120 --> 08:47.160]  이를 위해서는 어떤 데이터 형태가 있고 어떤 머신러닝 딥러닝 방법론이 있는지 먼저 아는게 중요하겠죠.

[08:47.160 --> 08:55.520]  그래서 딥러닝 머신러닝 3가지 타입에 대해서 설명을 드리고 그리고 각각 타입에 대한

[08:55.520 --> 09:07.880]  프로젝트를 짧게 소개를 드리도록 하겠습니다. 머신러닝 딥러닝은 슈퍼바이즈드 러닝, 언슈퍼바이즈드 러닝, 레인포스먼트 러닝 이렇게 세가지로 구분을 지을 수 있는데

[09:07.880 --> 09:19.040]  제가 각각의 타입에 대해서 설명도 드리고 그리고 수행했던 프로젝트도 얘기를 드리면서 좀 더 이해를 쉽게

[09:19.040 --> 09:24.160]  해드리도록 하겠습니다. 슈퍼바이즈드 러닝은

[09:25.880 --> 09:35.320]  한국말로는 교사학습, 의도학습 이라고 하는데 답이 주어져 있는 데이터와

[09:35.320 --> 09:40.480]  그리고 목적이 분명한

[09:40.560 --> 09:50.640]  테스크를 수행하는데 사용하는 러닝 방법인데 예를 들면 입력으로 탐이랑 그림

[09:50.640 --> 10:01.120]  강아지 그리고 고양이를 이렇게 넣었을 때 아웃풋은 아 이게 숫자고 그리고 개고 고양이 인지를 미리 아는 데이터를 넣어서

[10:01.120 --> 10:12.200]  이 y나 fx에 fx를 구하는게 슈퍼바이즈드 러닝입니다. 좀 더 슈퍼바이즈드 러닝을 쉽게 설명하면 슈퍼바이즈드 러닝은

[10:12.200 --> 10:22.480]  두가지 타입이 있는데 클래시피케이션이랑 리그레이션 두가지 타입이 있습니다. 클래시피케이션은 이렇게 녹색이랑

[10:22.480 --> 10:33.160]  파란색을 이런식으로 구분을 하는 분류형의 문제와 그리고 이렇게 이미지로 데이터가 이런식으로 선별적으로 되어 있을 때

[10:33.160 --> 10:45.040]  이런 리니어한 식을 나타내거나 혹은 2차식을 형성하는 그런 리그레이션 회기식 모델을 추출하는 두가지 경우가 있습니다.

[10:45.040 --> 10:57.600]  오른쪽 예를 보면 이거는 클래시피케이션 문제겠죠. 빨간색은 아이리스 이런 꽃이 있고 그리고 세토사라는 꽃이 있고 버지니아

[10:57.600 --> 11:08.760]  라는 꽃이 있는데 이런식으로 데이터가 왔을 때 이 세모는 여기군에 속하고 그 네모 빨간색은 여기에 속하고

[11:08.760 --> 11:19.280]  노란색 동그라미는 여기에 속하고 이런식으로 분류형의 문제에 속합니다. 이런 클래시피케이션이랑 리그레이션 문제는

[11:19.280 --> 11:28.000]  슈퍼바이즐러닝을 많이 사용합니다. 일반적으로 여러분들이 만약에 어떤 데이터를 가지고 예측을 하거나

[11:28.000 --> 11:35.200]  경향을 보고 싶을 때는 슈퍼바이즐러닝을 사용합니다.

[11:35.760 --> 11:43.280]  예전에도 제가 짧게 설명 드렸는데 이런 문제가 슈퍼바이즐러닝의

[11:43.280 --> 11:53.480]  하나의 예제입니다. 이 알고리즘의 개발 목적은 공조복합제어 기술을 통해서 건물에너지 절감 및

[11:53.480 --> 11:56.720]  최적환경 구현이었는데

[11:56.720 --> 12:03.840]  답이 나와있는 데이터라고 해야할까? 그게 무슨 말이냐면

[12:04.440 --> 12:16.640]  지금 데이터는 각각 시간에 대해서 그러니까 만약에 12시에는 20도, 새벽 1시에는 18도, 새벽 2시에는 17도,

[12:16.640 --> 12:23.640]  16도, 15도 이런식으로 시간에 따르면 다 데이터가 있고 그리고

[12:23.640 --> 12:29.280]  이제 새벽 6시, 7시에도 다 데이터가 있잖아요.

[12:29.280 --> 12:40.320]  근데 이제 이거가 하고자 하는 목표는 다음날 새벽 6시에 몇도, 다음날 아침 9시에 몇도 이런식으로 예측을 하면서

[12:40.320 --> 12:49.840]  그거에 알맞은 제어를 하는 건데 각각 시간에 대해서 데이터가 다 정답이 있는 레이블이 있는 데이터 세트였으니까

[12:49.840 --> 13:03.000]  이거는 prediction, regression 예측을 회기 모델로 구현하는 supervised learning이 될거고

[13:03.000 --> 13:12.280]  예전에도 설명을 드렸는데 기존의 알고리즘은 만약에 아침 8시 출근이면

[13:12.280 --> 13:25.960]  이미대로 새벽 6시에 난방을 켭니다. 근데 지금 여기서 하고자 하는 것은 아침 8시에 정확한 온도를 맞추기 위해서는 굳이 새벽 8시에 미리 켜서

[13:25.960 --> 13:37.200]  이만큼의 낭비되는 에너지를 만들기 싫다는 거죠. 그래서 이 최적 시작점을 인공지능을 통해서 학습을 하고

[13:37.200 --> 13:45.160]  학습 데이터가 실내온도, 외기온도 그리고 출근시간 이런식으로 되고

[13:45.160 --> 13:53.040]  이런 제어 값은 시오톤 온도, 외기온도, 실내온도 이런 걸로 제어를 하는데

[13:53.040 --> 14:02.680]  사실 여기서 복합제어까지 가기 전에 그 최적점의 난방 시작 시간과 난방 종료 시간을

[14:02.680 --> 14:07.600]  산출하는 것이 이 프로젝트의 목표였습니다.

[14:08.960 --> 14:16.320]  그래서 이 프로젝트는 Artificial Neural Network, ANN 이라고 하기도 하고

[14:16.320 --> 14:23.320]  MLP 멀티레이어 펄셉트론 이라고도 하는데 그냥 가장 기본적인 딥러닝

[14:23.320 --> 14:30.440]  유럴 네트워크의 모델을 사용해서 최적 시간을 설정한 프로젝트였습니다.

[14:30.440 --> 14:40.320]  이 인공신경망이 어떻게 작동하고 동작하는지는 수업하면서 하나하나 알려드리도록 하고

[14:40.320 --> 14:47.440]  그리고 실제로도 파이썬으로도 구현하면서 각각 인풋 데이터가 뭐고

[14:47.440 --> 14:54.680]  데이터가 뭔지는 하나하나 해보면서 제가 설명을 드리도록 하겠습니다.

[14:56.680 --> 15:05.040]  그래서 이렇게 최적 시간 설정과 그리고 최적 정지 시간 설정은 인공신경망으로 한 과업이 되고

[15:05.040 --> 15:09.680]  이게 Supervised Learning의 첫번째 예제 프로젝트가 되겠습니다.

[15:09.680 --> 15:21.200]  이런식으로 해서 실제 기술을 적용한 구간과 그리고 적용하지 않은 구간과 인공신경망의 기술을 적용한 구간의

[15:21.200 --> 15:29.080]  에너지 사용량에 대해서 실제로 조사를 했고 이 건물 같은 경우에는 2층과 3층이

[15:29.080 --> 15:36.560]  동일한 설비 모델로 구성이 되어 있었기 때문에

[15:36.560 --> 15:47.840]  각 기간별 어떤 기간은 실제 알고리즘을 적용한 구간에 대해서

[15:47.840 --> 15:56.360]  에너지를 뽑았고 다른 기간에 대해서는 기존의 알고리즘에 대한 제어 방법으로

[15:56.360 --> 16:05.000]  에너지를 산출한 결과를 뽑아서 비교를 했습니다. 그랬더니 기술을 적용한 구간이 25%

[16:05.000 --> 16:10.480]  에너지 절감을 한 결과를 얻었으며

[16:10.600 --> 16:15.880]  지금도 EMS 모델에는 이 모델이 실려있는 걸로 알고 있습니다.

[16:15.880 --> 16:20.400]  이렇게 Supervised Learning은

[16:20.400 --> 16:31.000]  이런 예측이죠. 근데 예측인데 클래시피케이션 그러니까 O 아니면 X 남 아니면 여 이런 클래시피케이션 문제가 아니고 이 문제는

[16:31.000 --> 16:44.080]  다음 날 혹은 1시간 뒤 1분 뒤에 어떤 온도를 맞출 것이냐 이 공조기를 켰을 때 그렇게 회귀 값에 대해서 회귀에 대한

[16:44.080 --> 16:51.480]  프로젝트를 진행했기 때문에 이거는 앞서 말한 리그레이션에 해당합니다.

[16:53.520 --> 17:01.280]  그리고 제가 아까 말씀드렸던 Supervised Learning이 아니고 Unsupervised Learning 문제인데

[17:01.280 --> 17:08.880]  Unsupervised Learning은 지금 그림에 나와 있듯이 X는 있는데 Y에 대한 값이 없어요. 그러니까

[17:08.880 --> 17:17.640]  유지수는 2개고 방정식은 하나 잖아요. 그러면 이거는 일반적으로 수학을 했을 때

[17:17.640 --> 17:24.280]  할 수 없는 문제로 정의를 합니다. Unsupervised Learning은 보통

[17:24.280 --> 17:31.120]  이런식으로 유사한 그룹끼리 클러스터링, 군집하는 문제가 많은데

[17:31.120 --> 17:42.120]  지금 여기서 그림을 보시면 회색 사람들이 이렇게 있는데 이미대로 녹색 사람들, 파란색, 빨간색, 보라색 이런식으로

[17:42.120 --> 17:53.560]  군집을 시켜놓은 이 녹색, 파란색, 빨간색, 보라색은 어떤 정답, 레이블이 있어서 이렇게 나눈게 아니고

[17:53.560 --> 18:02.640]  그냥 사용자 혹은 데이터에 의해서 이런식으로

[18:02.640 --> 18:10.560]  클러스터링을 한 문제거든요. 클러스터링은 보통

[18:10.560 --> 18:22.120]  이런 쪽 생명 쪽에 막 이렇게 여러개만 지금 어떻게 클래시피케이션을 할 수 없는, 레이블이 없는 이런

[18:22.560 --> 18:29.080]  DNA를 분석할때 그냥 이미대로 이런 색깔의 변화나

[18:29.920 --> 18:37.680]  SD의 밀집도의 변화에 따라서 달라지는 데이터의 양상을 보고 이미대로 클러스터링을 하는 것이

[18:37.680 --> 18:41.720]  또 문제입니다.

[18:41.920 --> 18:50.520]  네 그리고 이런 클러스터링 문제뿐만 아니라 사실 정의할 수 없는 y 값에 대해서 정의할 수 없는 문제에 대해서도

[18:51.520 --> 18:59.160]  Unsupervised learning이 들어가는데 제가 저번에 설명했던 프로젝트 중에서 FDD, Fault Detection and Diagnosis라는

[18:59.160 --> 19:08.760]  프로젝트가 있는데 이거는 설비 쪽의 고장진단에 대한 프로젝트인데 사실 설비의 고장진단을 그냥 만약에 설비

[19:08.760 --> 19:17.760]  서플라이펜이나 급기펜, 그러니까 급기펜이 고장났다고 했으면 급기펜 내부의 상태를 점검해주면 제일 빠른 방법이지만

[19:17.760 --> 19:26.280]  그러지 말고 서플라이펜과 연계된 이런 온도 센서나 압력 센서 등을 다 보면서

[19:26.280 --> 19:33.960]  온도 센서가 이상한데 이게 서플라이펜 문제가 아니고 만약에 힛 익스체인저, 열교환기 문제 혹은

[19:33.960 --> 19:44.920]  댐포대 문제 이런 식으로 찾아주는게 이 과제였는데 사실 온도 하나 혹은 압력 하나 혹은 유량계나 풍량계의 값에 따라서

[19:44.920 --> 19:55.440]  그런 특정 성분에 대한 분석을 추출하는게 굉장히 힘듭니다. 그리고 이 고장에 대한 정도를 정해준 것이 아니기 때문에

[19:55.440 --> 20:04.600]  이거는 정답이 없는 Unlabeled한 문제이기 때문에 이건 Unsupervised Learning과 Semi-Supervised Learning이라고 하는데

[20:04.600 --> 20:12.280]  Supervised Learning이지만 어떤 문제를 정의할 수 없는 구간구간에 대해서 Unsupervised Learning으로 프리트레이닝 그러니까

[20:12.280 --> 20:21.680]  미리 트레이닝을 한 모델을 들고 와서 수행을 합니다. 이거는 제가 또 다음 시간에 좀 더 자세히

[20:21.680 --> 20:30.040]  Python 스크립트나 한번 알고 있으면 제가 제대로 설명을 할 기회가 있으면 설명을 해드리도록 하는데

[20:30.040 --> 20:39.600]  아무튼 이 문제도 Unsupervised Learning과 그러니까 Deep Belief Network과 Unsupervised Learning 플러스 그리고 이제 Supervised Learning으로

[20:39.600 --> 20:52.960]  고장 진단을 한 프로젝트인데 임의대로 고장에 대한 데이터는 Modelica라는 시뮬레이션 툴을 사용해서 만들고

[20:52.960 --> 21:04.200]  정상은 그냥 일반적인 정상 데이터를 받아서 만들어서 이 두개를 Machine Learning Framework에 학습을 시켜서

[21:04.240 --> 21:12.800]  임의의 데이터가 들어왔을 때 이것이 고장인지 혹은 고장이 아닌지 고장이면 어떤 고장인지를 판단하는 프로젝트가 되겠습니다.

[21:12.800 --> 21:18.760]  이런 식으로 하나하나의 레이어별로

[21:18.760 --> 21:29.720]  이건 조금 어려운 내용인데 레이어별로 이런 레이블이 없기 때문에 레이어별로의 그 레이블을 임의대로 설정해주는 Unsupervised Learning인데

[21:29.720 --> 21:39.960]  이거는 기회가 되면 제가 나중에 설명을 드리고 혹은 시간이 없으면 제가 이 관련된 논문을 올려드리도록 하겠습니다.

[21:39.960 --> 21:48.880]  이게 RBM 이라는 레이어를 사용한 모델인데 이거는 캐나다의 정말 유명한 교수인 흰등 교수가

[21:48.880 --> 21:58.800]  그 당시에 이 논문을 발표함으로써 엄청난 주목도 받았고 Restrict Boltzmann Machine 모델을 사용해서

[21:58.800 --> 22:10.360]  이렇게 정의할 수 없는 레이블에 대한 레이어별로 이렇게 Unsupervised Learning을 하면서 결국에는 Supervised Learning을 위한 프레임워크를 짠 구조인데

[22:10.360 --> 22:16.120]  아무튼 이런 식으로 각각의 정의할 수 없는 데이터에 대해서

[22:16.120 --> 22:25.440]  수행한 프로젝트입니다. 이거는 결과는 저번 PPT에서 다 했으니까 보시면 될 것 같고

[22:25.480 --> 22:33.600]  이거는 Unsupervised Learning의 프로젝트가 아니고 Supervised Learning 프로젝트인데

[22:33.600 --> 22:39.760]  이것도 좀 설명을 드리면 이게 왜 Supervised Learning의 프로젝트냐면

[22:39.760 --> 22:50.480]  이거는 태양광 예측에 대한 모듈을 생성하는 건데 태양광 예측을 Recurrent Neural Network로 수행을 해서

[22:50.480 --> 23:01.160]  아침시간 혹은 저녁시간 혹은 내일 그리고 비올때, 맑을때 예보 데이터를 통해서 태양광을 예측하는

[23:01.160 --> 23:06.480]  리그레이션에 해당하는 모델을 수행한 프로젝트입니다.

[23:07.680 --> 23:19.400]  이거는 예전 현대건설연구소 Green Smart Innovation Center를 대상으로 태양광 예측 모델을 만든거고

[23:20.400 --> 23:29.000]  데이터는 이런 식으로 추출을 해서 이런 식으로가 어떤 식이냐면

[23:29.480 --> 23:35.280]  우리나라 예보 데이터가 히스토릭 데이터를 따로 저장하지 않는데 그래서

[23:35.280 --> 23:45.520]  2014년 9월부터 계속 데이터를 모아뒀었어요. 그래서 2016년 11월까지 계속 모아두고

[23:45.520 --> 23:55.360]  2017년 9월까지 계속 모아두면서 예보 데이터에 대한 데이터를 개더링하고

[23:55.360 --> 24:02.920]  그리고 보시면 알겠지만 이게 3시간 단위로밖에 데이터를 받을 수 없어서

[24:02.920 --> 24:12.080]  각각의 그러니까 3시간에 따른 예측은 너무 타임 갭이 크기 때문에 1시간 혹은 30분으로

[24:12.080 --> 24:23.040]  인터폴레이션 보감법을 통해서 데이터를 생성해서 학습을 했습니다. 예보 데이터 보감법이란게 뭐냐면 만약에 0시에서 7시까지

[24:23.040 --> 24:35.400]  데이터가 있으면 1시, 2시에 대한 데이터는 없잖아요? 그럼 1시, 2시에 대한 데이터를 0시, 3시 혹은 앞선 21시, 0시, 3시 이런 식으로

[24:35.400 --> 24:45.560]  데이터의 경향을 보면서 가운데 시간에 대한 데이터를 추출하는게 보감법이라고 생각하시면 됩니다. 보감법은 데이터 인터폴레이션이라고

[24:45.560 --> 24:56.040]  얘기를 하는데 그런식으로 해서 데이터를 만들고 이 데이터를 학습해서 각각 시간에 맞는 태양강 예측 값을 찾아내는 프로젝트였습니다.

[24:56.040 --> 25:05.240]  예보 값은 풍향, 풍속, 외기, 습도, 하이코드라고

[25:05.240 --> 25:11.400]  맑을 때는 0이고 흐릴 때는 4 이런식으로 숫자를 나타내면서

[25:11.400 --> 25:19.240]  맑음과 흐림 그리고 비올 때의 값을 뿌려주는 값이고 프리스펙테이션은 강수량 그리고 리프트는

[25:19.240 --> 25:28.160]  태양고도 값인데 이런식으로 값을 받아서 태양강 생산량을 예측하는 프로젝트를 수행했습니다.

[25:28.160 --> 25:34.320]  물론 공조기의 온오프 시간은 당연히 데이터로 넣었구요.

[25:34.680 --> 25:42.920]  그랬을 때 뉴럴넷 덕후가 소프트웨크 머신 그리고 리콘트 뉴럴넷 그리고 다른 머신러닝 방법을 썼을 때

[25:42.920 --> 25:48.080]  리콘트 뉴럴넷이 가장 좋은 결과를 냈고

[25:48.120 --> 25:58.040]  타임 시리즈한 데이터라는 시간에 따라 들어오는 데이터를 타임 시리즈한 데이터라고 하는데

[25:58.040 --> 26:07.960]  타임 시리즈한 데이터를 학습할 때는 리콘트 뉴럴넷 덕후의 개념 계열의 LSTM이나 그리고 GRU 이런 모델을 사용했고

[26:07.960 --> 26:23.880]  지금은 트랜스포머나 레즈넷 이런 모델을 많이 사용합니다.

[26:23.880 --> 26:29.880]  그런식으로 해서 수행을 했던 프로젝트고

[26:29.920 --> 26:37.880]  그랬을 때 태양강 생산량 뿐만 아니라 에너지 소비량도 예측을 했는데

[26:37.880 --> 26:45.320]  에너지 소비량은 오피스 특징을 잘 생각하시면 이거는 예측을 하기가 쉽거든요

[26:45.320 --> 26:54.120]  이렇게 꺾인 점은 당연히 점유시간에 에너지를 잘 안쓰기 때문에 이런식으로 나오는 그래프가 많았고

[26:54.120 --> 27:00.240]  그래서 에너지 소비량 같은 경우에는 굉장히 예측하기 쉬웠는데

[27:00.240 --> 27:06.560]  태양강 생산량은 정말 예측이 좀 힘든 부분이 많았습니다.

[27:06.560 --> 27:16.240]  워낙 예보 데이터가 그렇게 좋지 않아서 비오는 날과 흐린 날의 경우에는 잘 예측을 못하는 경우가 많았는데

[27:16.240 --> 27:25.720]  이거는 제가 나중에 어떤 방법론을 썼는지는 자세히 말할 수 있는 시간이 있으면 말해드리도록 하겠습니다.

[27:25.720 --> 27:31.040]  이게 드랍아웃 제가 설명을 드릴 때 한번 설명을 드리도록 하겠습니다.

[27:31.040 --> 27:37.520]  드랍아웃은 뉴럴레터워크를 설명할 때 자세히 설명을 드리도록 하겠습니다.

[27:39.280 --> 27:44.320]  그리고 이제 하나 남았는데 강학습에 대해서 설명을 하려고 하는데

[27:44.360 --> 27:58.760]  2015년 네이처지에 이례적으로 비생명 분야에서 처음으로 네이처 표지를 장식한 논문이 있었는데

[27:58.760 --> 28:09.640]  이게 알파구 논문인데 이게 네이처지에 표지를 장식하면서 AI 시대가 열렸다고 보면 될 것 같아요.

[28:09.640 --> 28:20.840]  이 알파구에 들어간 알고리즘이 강학습이고 현재도 정말 강학습에 대한 논문들이 많이 나오고 있고

[28:20.840 --> 28:28.200]  어떻게 보면 현재 트렌디한 리서치 토픽이라고 생각하시면 됩니다.

[28:29.160 --> 28:39.720]  강학습은 일반적인 슈퍼바이즈드 러닝과 언슈퍼바이즈드 러닝과는 좀 다른 개념인데

[28:39.720 --> 28:48.200]  왜냐하면 슈퍼바이즈드 러닝과 언슈퍼바이즈드 러닝은 어쨌든 어떤 특정한 fx에 대해서

[28:48.360 --> 28:57.800]  와인 fx를 계속 만들어줬을 때 fx와 실제 fx와 계속 만들어주는 fx 간의 로스트험을 계속 미니마이즈 해야 되는데

[28:57.800 --> 29:09.240]  강학습은 이 리워드 값을 그러니까 어떤 액션을 취해줬을 때의 보상을 맥시마이즈 하는 쪽으로 학습을 하는 것이 기존과는 조금 달라요.

[29:09.320 --> 29:12.120]  예를들면

[29:14.840 --> 29:25.480]  에이전트라고 불리는 바둑이라고 생각하면 알파고라는 에이전트가 어떠한 바둑 액션을 줬을 때

[29:25.480 --> 29:36.680]  그 환경에 대한 변화가 나중에 몇 집 차이로 이길지에 대한 리워드 이런 보상이 계속 커지게 그러니까 꼭 이길 수 있도록

[29:36.680 --> 29:39.240]  리워드가

[29:39.560 --> 29:46.200]  맥시마이즈 되도록 학습을 하는게 강학습입니다.

[29:46.200 --> 29:55.880]  알파고 예를 들어보면 보통 알파고는 만약에 논문을 조금 읽어보시면

[29:55.880 --> 30:03.640]  레인포스모드 러닝을 썼다고 하는데 거기에 또 컨볼루션 뉴럴레터 어플을 썼다고 나오거든요

[30:03.640 --> 30:14.200]  그러면 조금 헷갈려요. 처음에 논문을 읽을 때 분명히 그 알파고는 레인포스모드 러닝을 썼다고 하는데 컨볼루션 뉴럴레터 어플이 나오니까

[30:14.200 --> 30:22.600]  조금 헷갈릴 수도 있는데 컨볼루션 뉴럴레터 어플은 이 Environment를 구성할 때 사용을 합니다.

[30:22.600 --> 30:31.480]  보통 학습을 구성할 때 이런 리워드 설계도 중요하지만 Environment, 현실을 대변하는 환경 구성이 정말 중요한데

[30:31.480 --> 30:40.920]  그 환경 구성을 하는게 시뮬레이터라고 하고 그 시뮬레이터로 컨볼루션 뉴럴레터 어플을 쓴게 알파고의 모델이라고 생각하시면 됩니다.

[30:41.080 --> 30:49.400]  게임으로 예를 들면, 그래서 이게 보통 강학습하면 게임을 예로 많이 들거든요

[30:49.400 --> 30:56.680]  어떤 게임을 했을 때, 왜냐하면 아까 말씀드렸듯이 이런 Environment 구성이 게임이 조금 구성하기가 편해서

[30:56.680 --> 31:03.800]  보통 모든 강학습의 프레임워크나 아니면은 이 기생플로 나온 것은 다 게임이라고 생각하시면 되요.

[31:03.800 --> 31:09.720]  그래서 이런 Environment 구성이 게임이 좀 편하기 때문에 이런식으로 게임일제가 많은데

[31:09.720 --> 31:18.120]  그래서 어떤 액션 그러니까 위아래 혹은 앞뒤 이런식으로 조이스틱으로 움직일 때가 액션이라고 하면은

[31:18.200 --> 31:28.360]  액션에 따른 화면에 이런 공룡인가 비행기가 왔다갔다 할 때의 점수를 리워드라고 생각하시면

[31:28.360 --> 31:38.360]  비행기가 왔다갔다 하는게 이런 액션을 주었을 때의 Environment에 변하고 Environment가 변했을 때의 점수가 리워드라고 생각하시면 됩니다.

[31:38.360 --> 31:49.400]  그래서 이런 리워드를 계속 맥시마이저 하는 방향으로 이런 프레임워크가 계속 학습을 하는거고, 이거를 강학습이라고 생각하시면 됩니다.

[31:49.400 --> 32:02.040]  그 알고리즘이 DQN인데, 이거는 제가 강학습 수업을 할 때 자세히 설명드리도록 하겠습니다.

[32:02.080 --> 32:10.560]  보통 강학습에서 정말 대표되는 알고리즘이 DQN, DDPG 이런식으로 있는데 이게 DQN이

[32:10.560 --> 32:20.840]  그냥 정말 베이직한 개념은 그거에요. 그 리워드를 계속 맥시마이저하게 하는 학습법이라고 생각하시면 됩니다.

[32:21.680 --> 32:25.720]  이거는 강학습에 대한 프로젝트였는데

[32:26.680 --> 32:38.800]  이게 제가 설비쪽 제어 쪽에 지금 많이 포커스해서 과제를 수행했었기 때문에 설비쪽 제어 쪽을 자세히 모르시면

[32:38.800 --> 32:46.600]  제가 한번 보충설명을 할 자료나 강의를 하나 더 진행을 하도록 하겠습니다.

[32:46.600 --> 32:58.080]  아무튼 이 설비쪽에서 보통 PID 제어를 하는데, 이 PID 제어가 뭐냐면 Proportional Integral Derivate 제어라고 하는데

[32:58.080 --> 33:05.520]  이게 뭐 한국말로 하면 비례적품미분제어 이런식으로 생각하시면 되는데

[33:05.520 --> 33:11.360]  보통 벨브나 펌프나 팬이나 전부 PID 제어가 기본 제어로 깔려 있습니다.

[33:11.360 --> 33:15.760]  근데 이 PID 제어는

[33:16.880 --> 33:24.680]  이런식으로 KP, KI, KD라는 상수텀을 가지고 있는 식입니다.

[33:24.680 --> 33:34.360]  근데 이 상수텀은 건물 초기에 임해 관리자가 KP, KI, KD값을 정해놓고 가거든요.

[33:34.360 --> 33:45.080]  근데 이 KP, KI, KD값은 정말 0에서 10,000가지 숫자가 다양해요. 근데 이 다양한 값들을 관리자는 당연히 다 찾을 수 없고

[33:45.080 --> 33:53.160]  그리고 변화하는 환경과 변화하는 부하에 대해서 이 식은 잘 제어를 할 수가 없는 구조에요.

[33:53.160 --> 34:01.880]  그래서 이 KP, KI, KD를 인공지능으로 찾아보자는게 이 프로젝트의 목표였고

[34:02.200 --> 34:11.560]  KP, KI, KD만 찾으면 되는게 아니고 이 플랜트 프로세스 그러니까 건물은 건물의 제어 방법이죠.

[34:11.560 --> 34:20.760]  이 건물을 제어했을 때 환경에 따른 KP, KI, KD가 정말 중요하기 때문에 KP, KI, KD를 맞춘다고 해서

[34:20.760 --> 34:29.160]  건물을 제대로 제어하는 것도 아니고 변화하는 플랜트 프로세스를 또 반영해서 KP, KI, KD를 찾아야 되기 때문에

[34:29.160 --> 34:39.640]  이 KP, KI, KD값은 정말 어마어마하죠. 그래서 이걸 관리자들이 잘 못찾고 당연히 그냥 default한 값을 넣는 경우가 정말 많은데

[34:39.640 --> 34:44.040]  음 그래서 이거를 방학습으로

[34:45.200 --> 34:55.520]  프로젝트를 수행한 경우고 이 아까 말씀드렸던 리워드에 해당하는 것은 만약에 온도라고 생각하시면 이 온도편차를 최소화하는

[34:55.520 --> 35:04.440]  그러니까 온도편차를 최소화하는게 어떻게 보면은 리워드를 맥시마이징 하는거죠. 저희는 온도를 잘 맞추기 위해서 PID를 쓰는거고

[35:04.440 --> 35:13.960]  PID에 KP, KI, KD를 찾는건데 이 온도를 잘 맞추는거니까 리워드를 맥시마이징 하는 방향으로 계속 학습을 하면서

[35:13.960 --> 35:20.360]  KP, KI, KD를 찾는 프로젝트가 이번 프로젝트였습니다.

[35:20.400 --> 35:32.560]  그래서 결과로 실제 결과는 이제 예를 들면 이런식으로 실제로는 PID값을 넣었을때 실제 기존에 KP, KI, KD를 넣었을때는 이런 값인데

[35:32.560 --> 35:39.080]  이제 이런 방학습으로 찾은 KP, KI, KD를 넣었을때는 이런식으로 엄청 잘 맞는 경우가 나옵니다.

[35:39.080 --> 35:49.120]  이게 온도만 잘 맞추면 되는게 아니고 벨브값도 처음에는 막 이런식으로 그냥 엄청 많은 양의 가스가 이렇게 분출되게

[35:49.120 --> 35:54.960]  벨브가 크게 이렇게 움직이는데 저희같은 경우에는 이런식으로

[35:54.960 --> 36:02.480]  궤도율도 작고 이제 가스 배출량도 작게 하면서 에너지를 세이빙하는 그런 과제입니다.

[36:05.800 --> 36:12.840]  이제 프로젝트랑 슈퍼바이즈 러닝 1, 슈퍼바이즈 러닝, 레인포스먼트 러닝에 대한 설명을 간단하게 마쳤고

[36:12.840 --> 36:21.400]  팔선, 넌파이랑 판다스, 그리고 사이클런을 진행하면서 좀 더 자세한 설명을 드리도록 하고

[36:21.400 --> 36:28.840]  그 모듈을 들어가기 앞서 제가 혹시나 넌파이랑 판다스를 설명할 때 리그레이션이나 클래시피케이션이나

[36:28.840 --> 36:34.560]  그리고 슈퍼바이즈 러닝이나 듀얼 레이터 이런식으로 제가

[36:34.560 --> 36:40.280]  사전 학습이 없는 상태에서 말을 할 수도 있기 때문에 이렇게 강의를 좀 조정을 했구요

[36:40.280 --> 36:45.960]  그리고 모델이나 알고리즘을 선택할 때

[36:46.080 --> 36:52.280]  여기도 나오죠. 만약에 클래시피케이션이면 범주를 예측하거나 리그레이션이면 숫자 예측, 숫자 예측이라는게

[36:52.280 --> 36:59.480]  그 아까도 말씀드렸듯이 어떤 경향성을 보이거나 프레딕션을 할 때 보통은 다 리그레이션이라고 생각하시면 됩니다.

[36:59.480 --> 37:04.840]  클래시피케이션은 범주라고 하는게 남녀 혹은

[37:04.840 --> 37:14.440]  오엑스 이런식으로 아니면 1집단, 2집단, 3집단 이런식으로 범주를 예측할 때 클래시피케이션이라고 생각하시면 되고

[37:14.440 --> 37:20.840]  클래시피케이션이랑 리그레이션은 정말 비슷한데 로스펑션 그러니까

[37:20.840 --> 37:29.200]  학습을 할 때 로스펑션을 정의해주는 경우가 있는데 이 로스펑션만 조금 바꿔주면 이 두가지의 모델은

[37:29.200 --> 37:35.840]  그리고 클러스터링은 아까도 말씀드렸듯이 군집에 대한 결과를 나타내거나 혹은

[37:35.840 --> 37:45.440]  레이블이 없는 데이터를 수행할 때 클러스터링을 많이 씁니다. 아, Unsupervised learning을 많이 씁니다.

[37:46.120 --> 37:52.280]  모델평가는 보통 이런식으로 쓰는데 정말 이거는

[37:52.280 --> 38:03.480]  타임 시리즈 데이터는 Naive라고 이런식의 결과를 나타내는 펑션을 쓰는데 그냥 이런거 다 무시하시고 예를 들면

[38:03.480 --> 38:12.200]  실제 데이터가 이건데 만약에 저희가 리그레이션으로 찾은 함수값이 이거에요. 그러면 이 오차는

[38:12.200 --> 38:20.320]  이 점과 이 펑션의 거리에 제곱에 루트를 씌우거나 제곱에 합을 하거나

[38:20.320 --> 38:30.800]  이런식으로 해서 하는게 지금 이 얘기입니다. 그래서 민스쿄어 데이터나 루트 민스쿄어 데이터는 한번 구글링을 해보셔서 어떤 의미인지

[38:30.800 --> 38:38.960]  찾으면 됩니다. 그냥 간단하게 진짜 실제 데이터와 저희가 예측한 데이터의 차이를 이런식으로 나타내니깐

[38:38.960 --> 38:43.520]  어떤걸 쓰셔도 사실은 상관은 없어요. 근데

[38:44.520 --> 38:54.640]  이런 타임 시리즈라는 데이터는 사실 저는 MAP를 많이 쓰긴 하지만

[38:54.640 --> 39:02.880]  보통 MSE나 RMSE를 써도 상관없습니다. 그러니까 이런 모델 평가에 대한 펑션은 사실

[39:02.880 --> 39:11.640]  용어가 다르고 또 수식도 다르지만 어떻게 보면 하나의 텀으로 수렴이 되거든요. 그냥 실제 데이터와 예측한 데이터의 차이

[39:11.680 --> 39:14.920]  이런식으로 생각을 하시면 됩니다.

[39:18.400 --> 39:27.080]  오늘 수업은 여기서 마치는데 질문이 있거나 그리고 또 제가 좀 더 추가적으로 설명해야 될 것은

[39:27.080 --> 39:29.720]  논문이나

[39:30.400 --> 39:38.200]  아니면 짤막한 강의 자료로 올리면서 보충을 해드리도록 하겠습니다.

[39:38.200 --> 39:42.120]  오늘 수업은 여기서 마치겠습니다. 감사합니다.
